{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8d6fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf  # Although imported, it's not directly used in this snippet\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import pandas as pd  # Assuming your data is in a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9738ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_1 = 'voiceassistant_v1.csv'\n",
    "\n",
    "# Load dataset\n",
    "voiceassistant_df = pd.DataFrame(pd.read_csv(DATA_DIR_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f1c619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "voiceassistant_df['label'] = le.fit_transform(voiceassistant_df['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b189ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16280/16280 [00:02<00:00, 6322.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize data\n",
    "dataset = Dataset.from_pandas(voiceassistant_df[[\"transcription\", \"label\"]])\n",
    "dataset = dataset.map(lambda x: tokenizer(x[\"transcription\"], truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9f54b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "train_ds, val_ds = train_test['train'], train_test['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c501c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fdba990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a7f6b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17340\\3203135188.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4884' max='4884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4884/4884 49:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4884, training_loss=0.0400867374105887, metrics={'train_runtime': 2982.2047, 'train_samples_per_second': 13.102, 'train_steps_per_second': 1.638, 'total_flos': 153277039754496.0, 'train_loss': 0.0400867374105887, 'epoch': 3.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40587f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_model\\\\tokenizer_config.json',\n",
       " 'saved_model\\\\special_tokens_map.json',\n",
       " 'saved_model\\\\vocab.txt',\n",
       " 'saved_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"saved_model\")\n",
    "tokenizer.save_pretrained(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37ad2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "    predicted_intent = le.inverse_transform([predicted_class_id])[0]\n",
    "    return predicted_intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79e7c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transcriptions = [\n",
    "    \"G-Assist, cancel trip hok baru masuk tadi.\",\n",
    "    \"Buleh check earning bulan ni?\",\n",
    "    \"Nak berhenti kejap, isi minyak jap\",\n",
    "    \"Jawab penumpang saya akan tiba 5 minit nanti\",\n",
    "    \"Saya nak rehat\",\n",
    "    \"Okey, ammik trip ni\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1115c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G-Assist, cancel trip hok baru masuk tadi. -> unknown\n",
      "Buleh check earning bulan ni? -> unknown\n",
      "Nak berhenti kejap, isi minyak jap -> Stop request\n",
      "Jawab penumpang saya akan tiba 5 minit nanti -> unknown\n",
      "Saya nak rehat -> unknown\n",
      "Okey, ammik trip ni -> unknown\n"
     ]
    }
   ],
   "source": [
    "for transcript in new_transcriptions:\n",
    "    intent = predict_intent(transcript)\n",
    "    print(f\"{transcript} -> {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ba6c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dbe2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info >= (3, 13):\n",
    "    import types\n",
    "    # åˆ›å»ºä¸€ä¸ªç©ºæ¨¡å—ï¼Œå¡«å……åˆ° sys.modules ä¸­ï¼Œä»¥é˜²æ­¢ httpx ä¾èµ–æ—¶æ‰¾ä¸åˆ° cgi æ¨¡å—\n",
    "    sys.modules[\"cgi\"] = types.ModuleType(\"cgi\")\n",
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "import whisper\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "import requests\n",
    "import re\n",
    "import ffmpeg\n",
    "from googletrans import Translator  # éœ€è¦å®‰è£… googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d44fa7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½® Homebrew çš„ ffmpeg è·¯å¾„ï¼ˆmacOS ç”¨æˆ·ï¼‰\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d2dea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_DAVID_11.0 Microsoft David Desktop - English (United States) []\n",
      "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0 Microsoft Zira Desktop - English (United States) []\n",
      "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_ZH-CN_HUIHUI_11.0 Microsoft Huihui Desktop - Chinese (Simplified) []\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ– TTS å¼•æ“å¹¶è®¾ç½®çº¯è‹±æ–‡è¯­éŸ³\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)\n",
    "engine.setProperty('volume', 1.0)\n",
    "# åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„è¯­éŸ³ï¼ˆè°ƒè¯•ç”¨ï¼‰\n",
    "voices = engine.getProperty('voices')\n",
    "for voice in voices:\n",
    "    print(voice.id, voice.name, voice.languages)\n",
    "# å¼ºåˆ¶ä½¿ç”¨çº¯è‹±æ–‡è¯­éŸ³ï¼Œå¦‚ macOS ä¸Šçš„ \"Alex\"\n",
    "engine.setProperty('voice', \"com.apple.speech.synthesis.voice.Alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d60c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenWeather API Keyï¼ˆè¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„å®é™… API Keyï¼‰\n",
    "OPENWEATHER_API_KEY = \"060ade3304c10d0137387e263293f718\"\n",
    "\n",
    "# æ”¯æŒè¯†åˆ«çš„åŸå¸‚åˆ—è¡¨ï¼ˆå¯è‡ªè¡Œæ‰©å±•ï¼‰\n",
    "SUPPORTED_CITIES = [\n",
    "    \"Kuala Lumpur\", \"Penang\", \"Johor Bahru\", \"Ipoh\", \"Kuantan\", \"Melaka\", \"Seremban\",\n",
    "    \"Singapore\", \"Bangkok\", \"Jakarta\", \"Taipei\", \"Hong Kong\", \"Shanghai\", \"Beijing\",\n",
    "    \"Tokyo\", \"New York\", \"London\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b13daf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½ Whisper æ¨¡å‹\n",
    "print(\"Loading Whisper model...\")\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bf5b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    print(f\"Assistant says: {text}\")\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5140d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(filename='output.wav', duration=5, sample_rate=44100):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float64')\n",
    "    sd.wait()\n",
    "    print(\"Recording finished.\")\n",
    "    audio = np.int16(audio / np.max(np.abs(audio)) * 32767)\n",
    "    write(filename, sample_rate, audio)\n",
    "    print(f\"Audio saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0bc7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_english(text):\n",
    "    try:\n",
    "        translator = Translator()\n",
    "        translation = translator.translate(text, dest='en')\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(\"Translation error:\", e)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f3dc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio_path):\n",
    "    print(\"Transcribing...\")\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    print(f\"Detected language: {result['language']}\")\n",
    "    original_text = result['text']\n",
    "    print(\"Original transcription:\", original_text)\n",
    "    translated_text = translate_to_english(original_text)\n",
    "    print(\"Translated transcription:\", translated_text)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc8675d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND_KEYWORDS = {\n",
    "#     \"navigate\": [\"navigate\", \"go to\", \"directions\", \"å¯¼èˆª\", \"å»\", \"navigasi\", \"pergi ke\"],\n",
    "#     \"job\": [\"job\", \"accept job\", \"start work\", \"take order\", \"æ¥å•\", \"å¼€å§‹\", \"mula kerja\", \"terima pesanan\"],\n",
    "#     \"music\": [\"music\", \"play\", \"play music\", \"æ’­æ”¾éŸ³ä¹\", \"éŸ³ä¹\", \"main muzik\"],\n",
    "#     \"stop\": [\"stop\", \"exit\", \"shutdown\", \"åœæ­¢\", \"å…³æ‰\", \"berhenti\"],\n",
    "#     \"settings\": [\"settings\", \"open settings\", \"è®¾ç½®\", \"tetapan\"],\n",
    "#     \"weather\": [\"weather\", \"what's the weather\", \"check weather\", \"å¤©æ°”\", \"å¤©æ°£\", \"cuaca\"],\n",
    "#     \"call\": [\"call\", \"call someone\", \"æ‰“ç”µè¯\", \"hubungi\"]\n",
    "# }\n",
    "\n",
    "# def interpret_command(text):\n",
    "#     text = text.lower()\n",
    "#     for command, keywords in COMMAND_KEYWORDS.items():\n",
    "#         if any(k in text for k in keywords):\n",
    "#             return command\n",
    "#     return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d93b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(text):\n",
    "    for city in SUPPORTED_CITIES:\n",
    "        if city.lower() in text.lower():\n",
    "            return city\n",
    "    return \"Kuala Lumpur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f1b85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city=\"Kuala Lumpur\"):\n",
    "    try:\n",
    "        print(f\"[Weather API] Requesting weather for: {city}\")\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={'060ade3304c10d0137387e263293f718'}&units=metric\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if response.status_code == 200:\n",
    "            temp = data['main']['temp']\n",
    "            desc = data['weather'][0]['description']\n",
    "            msg = f\"The current weather in {city} is {desc} with {temp} degrees Celsius.\"\n",
    "            return msg\n",
    "        elif response.status_code == 401:\n",
    "            print(\"[Weather API Error]\", data)\n",
    "            return \"Invalid API key for weather service. Please check your API key.\"\n",
    "        else:\n",
    "            print(\"[Weather API Error]\", data)\n",
    "            return \"Sorry, I couldn't fetch the weather right now.\"\n",
    "    except Exception as e:\n",
    "        print(\"[Weather Exception]\", e)\n",
    "        return \"There was an error retrieving the weather.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9076891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_command(command, full_text):\n",
    "    if command == \"WEATHER CHECK\":\n",
    "        city = extract_city(full_text)\n",
    "        msg = get_weather(city)\n",
    "    else:\n",
    "        RESPONSES = {\n",
    "            \"NAVIGATE CHECK\": \"Alright, starting the fastest route to your passenger now.\",\n",
    "            \"ACCEPT BOOKING\": \"Great! You've accepted the job. Let's get going.\",\n",
    "            \"REJECT BOOKING\": \"No worries. I've declined the request for you.\",\n",
    "            \"TRAFFIC CHECK\": \"Let me check... Looks like the traffic is smooth ahead.\",\n",
    "            \"CHECK EARNING\": \"You've earned RM100 so far today. Keep it up!\",\n",
    "            \"STOP REQUEST\": \"Alright, ending the session now. Take care!\",\n",
    "            \"UNKNOWN\": \"Sorry, I didnâ€™t catch that. Could you please repeat your command?\",\n",
    "        }\n",
    "        msg = RESPONSES.get(command, RESPONSES[command])\n",
    "    print(f\"Assistant: {msg}\")\n",
    "    speak(msg)\n",
    "    return False if command == \"STOP REQUEST\" else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6d1d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_and_predict(audio_path):\n",
    "    print(\"Transcribing...\")\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    print(\"Transript:\", result['text'])\n",
    "    # translated_text = translate_to_english(result['text'])\n",
    "    # print(\"Translated:\", translated_text)\n",
    "\n",
    "    inputs = tokenizer(result['text'], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "    predicted_intent = le.inverse_transform([predicted_class_id])[0]\n",
    "    # intent = predict_intent(translated_text)\n",
    "    print(\"Predicted intent:\", predicted_intent)\n",
    "    return result['text'], predicted_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "921ba3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    print(\"Multilingual Voice Assistant Started â€” Say anything in any language!\")\n",
    "    speak(\"Hello! Please speak your command.\")\n",
    "    while True:\n",
    "        filename = \"output.wav\"\n",
    "        record_audio(filename=filename, duration=5)\n",
    "        if os.path.exists(filename):\n",
    "            text, command = transcribe_and_predict(filename)\n",
    "            if not respond_to_command(command, text):\n",
    "                break\n",
    "        else:\n",
    "            print(\"Audio file not found.\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "254388d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilingual Voice Assistant Started â€” Say anything in any language!\n",
      "Assistant says: Hello! Please speak your command.\n",
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as output.wav\n",
      "Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transript: cha\n",
      "Predicted intent: Navigate check\n",
      "Assistant: Alright, starting the fastest route to your passenger now.\n",
      "Assistant says: Alright, starting the fastest route to your passenger now.\n",
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as output.wav\n",
      "Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transript:  Well it rained later.\n",
      "Predicted intent: unknown\n",
      "Assistant: Sorry, I didnâ€™t catch that. Could you please repeat your command?\n",
      "Assistant says: Sorry, I didnâ€™t catch that. Could you please repeat your command?\n",
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as output.wav\n",
      "Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transript:  ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤· ğŸ¤·\n",
      "Predicted intent: Stop request\n",
      "Assistant: Alright, ending the session now. Take care!\n",
      "Assistant says: Alright, ending the session now. Take care!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
